{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace7c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ComputationalGraphPrimer import *\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f9bbd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDPlus(ComputationalGraphPrimer):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "    \n",
    "    def run_training_loop_one_neuron_model(self, training_data,mu=0.0,SGDplus=False):\n",
    "        \"\"\"\n",
    "        The training loop must first initialize the learnable parameters.  Remember, these are the \n",
    "        symbolic names in your input expressions for the neural layer that do not begin with the \n",
    "        letter 'x'.  In this case, we are initializing with random numbers from a uniform distribution \n",
    "        over the interval (0,1).\n",
    "        \"\"\"\n",
    "        self.vals_for_learnable_params = {param: random.uniform(0,1) for param in self.learnable_params}\n",
    "\n",
    "        self.bias = random.uniform(0,1)                   ## Adding the bias improves class discrimination.\n",
    "                                                          ##   We initialize it to a random number.\n",
    "\n",
    "        class DataLoader:\n",
    "            \"\"\"\n",
    "            To understand the logic of the dataloader, it would help if you first understand how \n",
    "            the training dataset is created.  Search for the following function in this file:\n",
    "\n",
    "                             gen_training_data(self)\n",
    "           \n",
    "            As you will see in the implementation code for this method, the training dataset\n",
    "            consists of a Python dict with two keys, 0 and 1, the former points to a list of \n",
    "            all Class 0 samples and the latter to a list of all Class 1 samples.  In each list,\n",
    "            the data samples are drawn from a multi-dimensional Gaussian distribution.  The two\n",
    "            classes have different means and variances.  The dimensionality of each data sample\n",
    "            is set by the number of nodes in the input layer of the neural network.\n",
    "\n",
    "            The data loader's job is to construct a batch of samples drawn randomly from the two\n",
    "            lists mentioned above.  And it mush also associate the class label with each sample\n",
    "            separately.\n",
    "            \"\"\"\n",
    "            def __init__(self, training_data, batch_size):\n",
    "                self.training_data = training_data\n",
    "                self.batch_size = batch_size\n",
    "                self.class_0_samples = [(item, 0) for item in self.training_data[0]]   ## Associate label 0 with each sample\n",
    "                self.class_1_samples = [(item, 1) for item in self.training_data[1]]   ## Associate label 1 with each sample\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.training_data[0]) + len(self.training_data[1])\n",
    "\n",
    "            def _getitem(self):    \n",
    "                cointoss = random.choice([0,1])                            ## When a batch is created by getbatch(), we want the\n",
    "                                                                           ##   samples to be chosen randomly from the two lists\n",
    "                if cointoss == 0:\n",
    "                    return random.choice(self.class_0_samples)\n",
    "                else:\n",
    "                    return random.choice(self.class_1_samples)            \n",
    "\n",
    "            def getbatch(self):\n",
    "                batch_data,batch_labels = [],[]                            ## First list for samples, the second for labels\n",
    "                maxval = 0.0                                               ## For approximate batch data normalization\n",
    "                for _ in range(self.batch_size):\n",
    "                    item = self._getitem()\n",
    "                    if np.max(item[0]) > maxval: \n",
    "                        maxval = np.max(item[0])\n",
    "                    batch_data.append(item[0])\n",
    "                    batch_labels.append(item[1])\n",
    "                batch_data = [item/maxval for item in batch_data]          ## Normalize batch data\n",
    "                batch = [batch_data, batch_labels]\n",
    "                return batch                \n",
    "\n",
    "        ##My input start\n",
    "        self.bias_update = 0.0\n",
    "        self.step = [0]*(len(self.learnable_params)+1)\n",
    "        self.mu = mu if SGDplus else 0.0      \n",
    "        \n",
    "        ##My input end\n",
    "        \n",
    "        \n",
    "        data_loader = DataLoader(training_data, batch_size=self.batch_size)\n",
    "        loss_running_record = []\n",
    "        i = 0\n",
    "        avg_loss_over_iterations = 0.0                                    ##  Average the loss over iterations for printing out \n",
    "                                                                           ##    every N iterations during the training loop.\n",
    "        for i in range(self.training_iterations):\n",
    "            data = data_loader.getbatch()\n",
    "            data_tuples = data[0]\n",
    "            class_labels = data[1]\n",
    "            y_preds, deriv_sigmoids =  self.forward_prop_one_neuron_model(data_tuples)              ##  FORWARD PROP of data\n",
    "            loss = sum([(abs(class_labels[i] - y_preds[i]))**2 for i in range(len(class_labels))])  ##  Find loss\n",
    "            loss_avg = loss / float(len(class_labels))                                              ##  Average the loss over batch\n",
    "            avg_loss_over_iterations += loss_avg                          \n",
    "            if i%(self.display_loss_how_often) == 0: \n",
    "                avg_loss_over_iterations /= self.display_loss_how_often\n",
    "                loss_running_record.append(avg_loss_over_iterations)\n",
    "                print(\"[iter=%d]  loss = %.4f\" %  (i+1, avg_loss_over_iterations))                 ## Display average loss\n",
    "                avg_loss_over_iterations = 0.0                                                     ## Re-initialize avg loss\n",
    "            y_errors = list(map(operator.sub, class_labels, y_preds))\n",
    "            y_error_avg = sum(y_errors) / float(len(class_labels))\n",
    "            deriv_sigmoid_avg = sum(deriv_sigmoids) / float(len(class_labels))\n",
    "            data_tuple_avg = [sum(x) for x in zip(*data_tuples)]\n",
    "            data_tuple_avg = list(map(operator.truediv, data_tuple_avg, \n",
    "                                     [float(len(class_labels))] * len(class_labels) ))\n",
    "            self.backprop_and_update_params_one_neuron_model(y_error_avg, data_tuple_avg, deriv_sigmoid_avg)     ## BACKPROP loss\n",
    "\n",
    "        return loss_running_record\n",
    "\n",
    "\n",
    "    def forward_prop_one_neuron_model(self, data_tuples_in_batch):\n",
    "        \"\"\"\n",
    "        Forward propagates the batch data through the neural network according to the equations on\n",
    "        Slide 50 of my Week 3 slides.\n",
    "\n",
    "        As the one-neuron model is characterized by a single expression, the main job of this function is\n",
    "        to evaluate that expression for each data tuple in the incoming batch.  The resulting output is\n",
    "        fed into the sigmoid activation function and the partial derivative of the sigmoid with respect\n",
    "        to its input calculated.\n",
    "        \"\"\"\n",
    "        output_vals = []\n",
    "        deriv_sigmoids = []\n",
    "        for vals_for_input_vars in data_tuples_in_batch:\n",
    "            input_vars = self.independent_vars                   ## This is a list of vars for the input nodes. For the\n",
    "                                                                 ##   the One-Neuron example in the Examples directory\n",
    "                                                                 ##   this is just the list [xa, xb, xc, xd]\n",
    "            vals_for_input_vars_dict =  dict(zip(input_vars, list(vals_for_input_vars)))   ## The current values at input\n",
    "\n",
    "            exp_obj = self.exp_objects[0]                        ## To understand this, first see the definition of the\n",
    "                                                                 ##   Exp class (search for the string \"class Exp\").\n",
    "                                                                 ##   Each expression that defines the neural network is\n",
    "                                                                 ##   represented by one Exp instance by the parser.\n",
    "            output_val = self.eval_expression(exp_obj.body , vals_for_input_vars_dict, self.vals_for_learnable_params)\n",
    "\n",
    "            ## [Search for \"self.bias\" in this file.]  As mentioned earlier, adding bias improves class discrimination:\n",
    "            output_val = output_val + self.bias\n",
    "\n",
    "            output_val = 1.0 / (1.0 + np.exp(-1.0 * output_val))   ## Apply sigmoid activation (output confined to [0.0,1.0] interval) \n",
    "\n",
    "            deriv_sigmoid = output_val * (1.0 - output_val)        ## See Slide 59 for why we need partial deriv of Sigmoid at input point\n",
    "\n",
    "            output_vals.append(output_val)                         ## Collect output values for different input samples in batch\n",
    "\n",
    "            deriv_sigmoids.append(deriv_sigmoid)                   ## Collect the Sigmoid derivatives for each input sample in batch\n",
    "                                                                   ##   The derivatives that are saved during forward prop are shown on Slide 59.\n",
    "        return output_vals, deriv_sigmoids\n",
    "\n",
    "\n",
    "    def backprop_and_update_params_one_neuron_model(self, y_error, vals_for_input_vars, deriv_sigmoid):\n",
    "        \"\"\"\n",
    "        As should be evident from the syntax used in the following call to backprop function,\n",
    "\n",
    "           self.backprop_and_update_params_one_neuron_model( y_error_avg, data_tuple_avg, deriv_sigmoid_avg)\n",
    "                                                                     ^^^             ^^^                ^^^\n",
    "        the values fed to the backprop function for its three arguments are averaged over the training \n",
    "        samples in the batch.  This in keeping with the spirit of SGD that calls for averaging the \n",
    "        information retained in the forward propagation over the samples in a batch.\n",
    "\n",
    "        See Slide 59 of my Week 3 slides for the math of back propagation for the One-Neuron network.\n",
    "        \"\"\"\n",
    "        input_vars = self.independent_vars\n",
    "        vals_for_input_vars_dict =  dict(zip(input_vars, list(vals_for_input_vars)))\n",
    "        vals_for_learnable_params = self.vals_for_learnable_params\n",
    "        for i,param in enumerate(self.vals_for_learnable_params):\n",
    "            ## My change start\n",
    "            self.step[i] = (self.mu*self.step[i]) +  y_error * vals_for_input_vars_dict[input_vars[i]] * deriv_sigmoid\n",
    "            \n",
    "            ## Update the learnable parameters\n",
    "            self.vals_for_learnable_params[param] += self.learning_rate*self.step[i]\n",
    "            \n",
    "        ## Update the bias\n",
    "        self.bias_update = (self.mu*self.bias_update) + y_error * deriv_sigmoid\n",
    "        self.bias += self.learning_rate*self.bias_update   \n",
    "            ##My change end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbce28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(ComputationalGraphPrimer):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "    \n",
    "    def run_training_loop_one_neuron_model(self, training_data,beta1,beta2):\n",
    "        \"\"\"\n",
    "        The training loop must first initialize the learnable parameters.  Remember, these are the \n",
    "        symbolic names in your input expressions for the neural layer that do not begin with the \n",
    "        letter 'x'.  In this case, we are initializing with random numbers from a uniform distribution \n",
    "        over the interval (0,1).\n",
    "        \"\"\"\n",
    "        self.vals_for_learnable_params = {param: random.uniform(0,1) for param in self.learnable_params}\n",
    "\n",
    "        self.bias = random.uniform(0,1)                   ## Adding the bias improves class discrimination.\n",
    "                                                          ##   We initialize it to a random number.\n",
    "\n",
    "        class DataLoader:\n",
    "            \"\"\"\n",
    "            To understand the logic of the dataloader, it would help if you first understand how \n",
    "            the training dataset is created.  Search for the following function in this file:\n",
    "\n",
    "                             gen_training_data(self)\n",
    "           \n",
    "            As you will see in the implementation code for this method, the training dataset\n",
    "            consists of a Python dict with two keys, 0 and 1, the former points to a list of \n",
    "            all Class 0 samples and the latter to a list of all Class 1 samples.  In each list,\n",
    "            the data samples are drawn from a multi-dimensional Gaussian distribution.  The two\n",
    "            classes have different means and variances.  The dimensionality of each data sample\n",
    "            is set by the number of nodes in the input layer of the neural network.\n",
    "\n",
    "            The data loader's job is to construct a batch of samples drawn randomly from the two\n",
    "            lists mentioned above.  And it mush also associate the class label with each sample\n",
    "            separately.\n",
    "            \"\"\"\n",
    "            def __init__(self, training_data, batch_size):\n",
    "                self.training_data = training_data\n",
    "                self.batch_size = batch_size\n",
    "                self.class_0_samples = [(item, 0) for item in self.training_data[0]]   ## Associate label 0 with each sample\n",
    "                self.class_1_samples = [(item, 1) for item in self.training_data[1]]   ## Associate label 1 with each sample\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.training_data[0]) + len(self.training_data[1])\n",
    "\n",
    "            def _getitem(self):    \n",
    "                cointoss = random.choice([0,1])                            ## When a batch is created by getbatch(), we want the\n",
    "                                                                           ##   samples to be chosen randomly from the two lists\n",
    "                if cointoss == 0:\n",
    "                    return random.choice(self.class_0_samples)\n",
    "                else:\n",
    "                    return random.choice(self.class_1_samples)            \n",
    "\n",
    "            def getbatch(self):\n",
    "                batch_data,batch_labels = [],[]                            ## First list for samples, the second for labels\n",
    "                maxval = 0.0                                               ## For approximate batch data normalization\n",
    "                for _ in range(self.batch_size):\n",
    "                    item = self._getitem()\n",
    "                    if np.max(item[0]) > maxval: \n",
    "                        maxval = np.max(item[0])\n",
    "                    batch_data.append(item[0])\n",
    "                    batch_labels.append(item[1])\n",
    "                batch_data = [item/maxval for item in batch_data]          ## Normalize batch data\n",
    "                batch = [batch_data, batch_labels]\n",
    "                return batch                \n",
    "\n",
    "        ##My input start\n",
    "        self.bias_m = 0.0\n",
    "        self.bias_v = 0.0\n",
    "        \n",
    "        self.bias_mh = 0.0\n",
    "        self.bias_vh = 0.0\n",
    "        \n",
    "        self.step_m = [0]*(len(self.learnable_params)+1)\n",
    "        self.step_v = [0]*(len(self.learnable_params)+1) \n",
    "        self.step_mh = [0]*(len(self.learnable_params)+1)\n",
    "        self.step_vh = [0]*(len(self.learnable_params)+1) \n",
    "        \n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.m = 0\n",
    "        \n",
    "        ##My input end\n",
    "        \n",
    "        \n",
    "        data_loader = DataLoader(training_data, batch_size=self.batch_size)\n",
    "        loss_running_record = []\n",
    "        i = 0\n",
    "        avg_loss_over_iterations = 0.0                                    ##  Average the loss over iterations for printing out \n",
    "                                                                           ##    every N iterations during the training loop.\n",
    "        for i in range(self.training_iterations):\n",
    "            self.m = i+1\n",
    "            data = data_loader.getbatch()\n",
    "            data_tuples = data[0]\n",
    "            class_labels = data[1]\n",
    "            y_preds, deriv_sigmoids =  self.forward_prop_one_neuron_model(data_tuples)              ##  FORWARD PROP of data\n",
    "            loss = sum([(abs(class_labels[i] - y_preds[i]))**2 for i in range(len(class_labels))])  ##  Find loss\n",
    "            loss_avg = loss / float(len(class_labels))                                              ##  Average the loss over batch\n",
    "            avg_loss_over_iterations += loss_avg                          \n",
    "            if i%(self.display_loss_how_often) == 0: \n",
    "                avg_loss_over_iterations /= self.display_loss_how_often\n",
    "                loss_running_record.append(avg_loss_over_iterations)\n",
    "                print(\"[iter=%d]  loss = %.4f\" %  (i+1, avg_loss_over_iterations))                 ## Display average loss\n",
    "                avg_loss_over_iterations = 0.0                                                     ## Re-initialize avg loss\n",
    "            y_errors = list(map(operator.sub, class_labels, y_preds))\n",
    "            y_error_avg = sum(y_errors) / float(len(class_labels))\n",
    "            deriv_sigmoid_avg = sum(deriv_sigmoids) / float(len(class_labels))\n",
    "            data_tuple_avg = [sum(x) for x in zip(*data_tuples)]\n",
    "            data_tuple_avg = list(map(operator.truediv, data_tuple_avg, \n",
    "                                     [float(len(class_labels))] * len(class_labels) ))\n",
    "            self.backprop_and_update_params_one_neuron_model(y_error_avg, data_tuple_avg, deriv_sigmoid_avg)     ## BACKPROP loss\n",
    "\n",
    "        return loss_running_record\n",
    "\n",
    "\n",
    "    def forward_prop_one_neuron_model(self, data_tuples_in_batch):\n",
    "        \"\"\"\n",
    "        Forward propagates the batch data through the neural network according to the equations on\n",
    "        Slide 50 of my Week 3 slides.\n",
    "\n",
    "        As the one-neuron model is characterized by a single expression, the main job of this function is\n",
    "        to evaluate that expression for each data tuple in the incoming batch.  The resulting output is\n",
    "        fed into the sigmoid activation function and the partial derivative of the sigmoid with respect\n",
    "        to its input calculated.\n",
    "        \"\"\"\n",
    "        output_vals = []\n",
    "        deriv_sigmoids = []\n",
    "        for vals_for_input_vars in data_tuples_in_batch:\n",
    "            input_vars = self.independent_vars                   ## This is a list of vars for the input nodes. For the\n",
    "                                                                 ##   the One-Neuron example in the Examples directory\n",
    "                                                                 ##   this is just the list [xa, xb, xc, xd]\n",
    "            vals_for_input_vars_dict =  dict(zip(input_vars, list(vals_for_input_vars)))   ## The current values at input\n",
    "\n",
    "            exp_obj = self.exp_objects[0]                        ## To understand this, first see the definition of the\n",
    "                                                                 ##   Exp class (search for the string \"class Exp\").\n",
    "                                                                 ##   Each expression that defines the neural network is\n",
    "                                                                 ##   represented by one Exp instance by the parser.\n",
    "            output_val = self.eval_expression(exp_obj.body , vals_for_input_vars_dict, self.vals_for_learnable_params)\n",
    "\n",
    "            ## [Search for \"self.bias\" in this file.]  As mentioned earlier, adding bias improves class discrimination:\n",
    "            output_val = output_val + self.bias\n",
    "\n",
    "            output_val = 1.0 / (1.0 + np.exp(-1.0 * output_val))   ## Apply sigmoid activation (output confined to [0.0,1.0] interval) \n",
    "\n",
    "            deriv_sigmoid = output_val * (1.0 - output_val)        ## See Slide 59 for why we need partial deriv of Sigmoid at input point\n",
    "\n",
    "            output_vals.append(output_val)                         ## Collect output values for different input samples in batch\n",
    "\n",
    "            deriv_sigmoids.append(deriv_sigmoid)                   ## Collect the Sigmoid derivatives for each input sample in batch\n",
    "                                                                   ##   The derivatives that are saved during forward prop are shown on Slide 59.\n",
    "        return output_vals, deriv_sigmoids\n",
    "\n",
    "\n",
    "    def backprop_and_update_params_one_neuron_model(self, y_error, vals_for_input_vars, deriv_sigmoid):\n",
    "        \"\"\"\n",
    "        As should be evident from the syntax used in the following call to backprop function,\n",
    "\n",
    "           self.backprop_and_update_params_one_neuron_model( y_error_avg, data_tuple_avg, deriv_sigmoid_avg)\n",
    "                                                                     ^^^             ^^^                ^^^\n",
    "        the values fed to the backprop function for its three arguments are averaged over the training \n",
    "        samples in the batch.  This in keeping with the spirit of SGD that calls for averaging the \n",
    "        information retained in the forward propagation over the samples in a batch.\n",
    "\n",
    "        See Slide 59 of my Week 3 slides for the math of back propagation for the One-Neuron network.\n",
    "        \"\"\"\n",
    "        input_vars = self.independent_vars\n",
    "        vals_for_input_vars_dict =  dict(zip(input_vars, list(vals_for_input_vars)))\n",
    "        vals_for_learnable_params = self.vals_for_learnable_params\n",
    "        for i,param in enumerate(self.vals_for_learnable_params):\n",
    "            ## My change start\n",
    "            self.step_m[i] = (self.beta1*self.step_m[i]) + (1-self.beta1)*(y_error * vals_for_input_vars_dict[input_vars[i]] * deriv_sigmoid)\n",
    "            self.step_mh[i] = self.step_m[i]/(1-self.beta1**self.m)\n",
    "            \n",
    "            self.step_v[i] = (self.beta2*self.step_v[i]) + (1-self.beta2)*((y_error * vals_for_input_vars_dict[input_vars[i]] * deriv_sigmoid)**2)\n",
    "            self.step_vh[i] = self.step_v[i]/(1-self.beta2**self.m)\n",
    "\n",
    "            ## Update the learnable parameters\n",
    "            self.vals_for_learnable_params[param] += self.learning_rate * (self.step_mh[i]/(np.sqrt(self.step_vh[i])+10**-6))\n",
    "            \n",
    "        ## Update the bias\n",
    "        self.bias_m = (self.beta1*self.bias_m) + (1-self.beta1)*(y_error * deriv_sigmoid)\n",
    "        self.bias_mh = self.bias_m/(1-self.beta1**self.m)\n",
    "        self.bias_v = (self.beta2*self.bias_v) + (1-self.beta2)*((y_error * deriv_sigmoid)**2)\n",
    "        self.bias_vh = self.bias_v/(1-self.beta2**self.m)\n",
    "        self.bias += self.learning_rate * (self.bias_m/(np.sqrt(self.bias_v)+10**-6)) \n",
    "            ##My change end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147f819a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "all variables: {'xb', 'xd', 'xc', 'xw', 'xa'}\n",
      "\n",
      "\n",
      "learnable params: ['ab', 'bc', 'cd', 'ac']\n",
      "\n",
      "\n",
      "dependencies: {'xw': ['xa', 'xb', 'xc', 'xd']}\n",
      "\n",
      "\n",
      "expressions dict: {'xw': 'ab*xa+bc*xb+cd*xc+ac*xd'}\n",
      "\n",
      "\n",
      "var_to_var_param dict:  {'xw': {'xa': 'ab', 'xb': 'bc', 'xc': 'cd', 'xd': 'ac'}}\n",
      "\n",
      "\n",
      "node to int labels:  {'xa': 0, 'xb': 1, 'xc': 2, 'xd': 3, 'xw': 4}\n",
      "\n",
      "\n",
      "independent vars: ['xb', 'xd', 'xc', 'xa']\n",
      "\n",
      "\n",
      "leads_to dictionary: {'xb': {'xw'}, 'xd': {'xw'}, 'xc': {'xw'}, 'xw': set(), 'xa': {'xw'}}\n"
     ]
    }
   ],
   "source": [
    "cgp1 = SGDPlus(\n",
    "               one_neuron_model = True,\n",
    "               expressions = ['xw=ab*xa+bc*xb+cd*xc+ac*xd'],\n",
    "               output_vars = ['xw'],\n",
    "               dataset_size = 5000,\n",
    "               learning_rate = 5 * 1e-3,\n",
    "#               learning_rate = 5 * 1e-2,\n",
    "               training_iterations = 40000,\n",
    "               batch_size = 8,\n",
    "               display_loss_how_often = 100,\n",
    "               debug = True,\n",
    "      )\n",
    "\n",
    "\n",
    "cgp1.parse_expressions()\n",
    "training_data1 = cgp1.gen_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3c338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "all variables: {'xb', 'xd', 'xc', 'xw', 'xa'}\n",
      "\n",
      "\n",
      "learnable params: ['ab', 'bc', 'cd', 'ac']\n",
      "\n",
      "\n",
      "dependencies: {'xw': ['xa', 'xb', 'xc', 'xd']}\n",
      "\n",
      "\n",
      "expressions dict: {'xw': 'ab*xa+bc*xb+cd*xc+ac*xd'}\n",
      "\n",
      "\n",
      "var_to_var_param dict:  {'xw': {'xa': 'ab', 'xb': 'bc', 'xc': 'cd', 'xd': 'ac'}}\n",
      "\n",
      "\n",
      "node to int labels:  {'xa': 0, 'xb': 1, 'xc': 2, 'xd': 3, 'xw': 4}\n",
      "\n",
      "\n",
      "independent vars: ['xb', 'xd', 'xc', 'xa']\n",
      "\n",
      "\n",
      "leads_to dictionary: {'xb': {'xw'}, 'xd': {'xw'}, 'xc': {'xw'}, 'xw': set(), 'xa': {'xw'}}\n"
     ]
    }
   ],
   "source": [
    "cgp2 = Adam(\n",
    "               one_neuron_model = True,\n",
    "               expressions = ['xw=ab*xa+bc*xb+cd*xc+ac*xd'],\n",
    "               output_vars = ['xw'],\n",
    "               dataset_size = 5000,\n",
    "               learning_rate = 5 * 1e-3,\n",
    "#               learning_rate = 5 * 1e-2,\n",
    "               training_iterations = 40000,\n",
    "               batch_size = 8,\n",
    "               display_loss_how_often = 100,\n",
    "               debug = True,\n",
    "      )\n",
    "\n",
    "\n",
    "cgp2.parse_expressions()\n",
    "training_data2 = cgp2.gen_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdb63a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter=1]  loss = 0.0026\n",
      "[iter=101]  loss = 0.3524\n",
      "[iter=201]  loss = 0.3234\n",
      "[iter=301]  loss = 0.3156\n",
      "[iter=401]  loss = 0.3466\n",
      "[iter=501]  loss = 0.3184\n",
      "[iter=601]  loss = 0.3183\n",
      "[iter=701]  loss = 0.3048\n",
      "[iter=801]  loss = 0.3348\n",
      "[iter=901]  loss = 0.2870\n",
      "[iter=1001]  loss = 0.3142\n",
      "[iter=1101]  loss = 0.3045\n",
      "[iter=1201]  loss = 0.2978\n",
      "[iter=1301]  loss = 0.3131\n",
      "[iter=1401]  loss = 0.2880\n",
      "[iter=1501]  loss = 0.2943\n",
      "[iter=1601]  loss = 0.2921\n",
      "[iter=1701]  loss = 0.2874\n",
      "[iter=1801]  loss = 0.2859\n",
      "[iter=1901]  loss = 0.2771\n",
      "[iter=2001]  loss = 0.2811\n",
      "[iter=2101]  loss = 0.2713\n",
      "[iter=2201]  loss = 0.2760\n",
      "[iter=2301]  loss = 0.2554\n",
      "[iter=2401]  loss = 0.2645\n",
      "[iter=2501]  loss = 0.2640\n",
      "[iter=2601]  loss = 0.2585\n",
      "[iter=2701]  loss = 0.2535\n",
      "[iter=2801]  loss = 0.2520\n",
      "[iter=2901]  loss = 0.2515\n",
      "[iter=3001]  loss = 0.2509\n",
      "[iter=3101]  loss = 0.2515\n",
      "[iter=3201]  loss = 0.2525\n",
      "[iter=3301]  loss = 0.2499\n",
      "[iter=3401]  loss = 0.2429\n",
      "[iter=3501]  loss = 0.2502\n",
      "[iter=3601]  loss = 0.2479\n",
      "[iter=3701]  loss = 0.2516\n",
      "[iter=3801]  loss = 0.2381\n",
      "[iter=3901]  loss = 0.2476\n",
      "[iter=4001]  loss = 0.2473\n",
      "[iter=4101]  loss = 0.2467\n",
      "[iter=4201]  loss = 0.2450\n",
      "[iter=4301]  loss = 0.2458\n",
      "[iter=4401]  loss = 0.2440\n",
      "[iter=4501]  loss = 0.2463\n",
      "[iter=4601]  loss = 0.2420\n",
      "[iter=4701]  loss = 0.2372\n",
      "[iter=4801]  loss = 0.2424\n",
      "[iter=4901]  loss = 0.2475\n",
      "[iter=5001]  loss = 0.2417\n",
      "[iter=5101]  loss = 0.2445\n",
      "[iter=5201]  loss = 0.2412\n",
      "[iter=5301]  loss = 0.2395\n",
      "[iter=5401]  loss = 0.2425\n",
      "[iter=5501]  loss = 0.2405\n",
      "[iter=5601]  loss = 0.2390\n",
      "[iter=5701]  loss = 0.2429\n",
      "[iter=5801]  loss = 0.2433\n",
      "[iter=5901]  loss = 0.2405\n",
      "[iter=6001]  loss = 0.2415\n",
      "[iter=6101]  loss = 0.2428\n",
      "[iter=6201]  loss = 0.2416\n",
      "[iter=6301]  loss = 0.2431\n",
      "[iter=6401]  loss = 0.2412\n",
      "[iter=6501]  loss = 0.2424\n",
      "[iter=6601]  loss = 0.2415\n",
      "[iter=6701]  loss = 0.2405\n",
      "[iter=6801]  loss = 0.2422\n",
      "[iter=6901]  loss = 0.2459\n",
      "[iter=7001]  loss = 0.2422\n",
      "[iter=7101]  loss = 0.2425\n",
      "[iter=7201]  loss = 0.2429\n",
      "[iter=7301]  loss = 0.2405\n",
      "[iter=7401]  loss = 0.2413\n",
      "[iter=7501]  loss = 0.2412\n",
      "[iter=7601]  loss = 0.2428\n",
      "[iter=7701]  loss = 0.2420\n",
      "[iter=7801]  loss = 0.2443\n",
      "[iter=7901]  loss = 0.2421\n",
      "[iter=8001]  loss = 0.2437\n",
      "[iter=8101]  loss = 0.2428\n",
      "[iter=8201]  loss = 0.2417\n",
      "[iter=8301]  loss = 0.2411\n",
      "[iter=8401]  loss = 0.2435\n",
      "[iter=8501]  loss = 0.2424\n",
      "[iter=8601]  loss = 0.2428\n",
      "[iter=8701]  loss = 0.2423\n",
      "[iter=8801]  loss = 0.2438\n",
      "[iter=8901]  loss = 0.2426\n",
      "[iter=9001]  loss = 0.2408\n",
      "[iter=9101]  loss = 0.2414\n",
      "[iter=9201]  loss = 0.2447\n",
      "[iter=9301]  loss = 0.2419\n",
      "[iter=9401]  loss = 0.2432\n",
      "[iter=9501]  loss = 0.2451\n",
      "[iter=9601]  loss = 0.2429\n",
      "[iter=9701]  loss = 0.2437\n",
      "[iter=9801]  loss = 0.2443\n",
      "[iter=9901]  loss = 0.2428\n",
      "[iter=10001]  loss = 0.2422\n",
      "[iter=10101]  loss = 0.2441\n",
      "[iter=10201]  loss = 0.2429\n",
      "[iter=10301]  loss = 0.2453\n",
      "[iter=10401]  loss = 0.2439\n",
      "[iter=10501]  loss = 0.2425\n",
      "[iter=10601]  loss = 0.2427\n",
      "[iter=10701]  loss = 0.2430\n",
      "[iter=10801]  loss = 0.2426\n",
      "[iter=10901]  loss = 0.2439\n",
      "[iter=11001]  loss = 0.2430\n",
      "[iter=11101]  loss = 0.2434\n",
      "[iter=11201]  loss = 0.2432\n",
      "[iter=11301]  loss = 0.2416\n",
      "[iter=11401]  loss = 0.2421\n",
      "[iter=11501]  loss = 0.2431\n",
      "[iter=11601]  loss = 0.2421\n",
      "[iter=11701]  loss = 0.2429\n",
      "[iter=11801]  loss = 0.2407\n",
      "[iter=11901]  loss = 0.2432\n",
      "[iter=12001]  loss = 0.2426\n",
      "[iter=12101]  loss = 0.2429\n",
      "[iter=12201]  loss = 0.2435\n",
      "[iter=12301]  loss = 0.2420\n",
      "[iter=12401]  loss = 0.2409\n",
      "[iter=12501]  loss = 0.2431\n",
      "[iter=12601]  loss = 0.2427\n",
      "[iter=12701]  loss = 0.2446\n",
      "[iter=12801]  loss = 0.2422\n",
      "[iter=12901]  loss = 0.2416\n",
      "[iter=13001]  loss = 0.2416\n",
      "[iter=13101]  loss = 0.2394\n",
      "[iter=13201]  loss = 0.2414\n",
      "[iter=13301]  loss = 0.2410\n",
      "[iter=13401]  loss = 0.2419\n",
      "[iter=13501]  loss = 0.2420\n",
      "[iter=13601]  loss = 0.2387\n",
      "[iter=13701]  loss = 0.2417\n",
      "[iter=13801]  loss = 0.2404\n",
      "[iter=13901]  loss = 0.2408\n",
      "[iter=14001]  loss = 0.2405\n",
      "[iter=14101]  loss = 0.2414\n",
      "[iter=14201]  loss = 0.2406\n",
      "[iter=14301]  loss = 0.2387\n",
      "[iter=14401]  loss = 0.2428\n",
      "[iter=14501]  loss = 0.2417\n",
      "[iter=14601]  loss = 0.2426\n",
      "[iter=14701]  loss = 0.2409\n",
      "[iter=14801]  loss = 0.2423\n",
      "[iter=14901]  loss = 0.2409\n",
      "[iter=15001]  loss = 0.2434\n",
      "[iter=15101]  loss = 0.2405\n",
      "[iter=15201]  loss = 0.2408\n",
      "[iter=15301]  loss = 0.2398\n",
      "[iter=15401]  loss = 0.2427\n",
      "[iter=15501]  loss = 0.2400\n",
      "[iter=15601]  loss = 0.2425\n",
      "[iter=15701]  loss = 0.2410\n",
      "[iter=15801]  loss = 0.2399\n",
      "[iter=15901]  loss = 0.2424\n",
      "[iter=16001]  loss = 0.2408\n",
      "[iter=16101]  loss = 0.2414\n",
      "[iter=16201]  loss = 0.2414\n",
      "[iter=16301]  loss = 0.2404\n",
      "[iter=16401]  loss = 0.2409\n",
      "[iter=16501]  loss = 0.2420\n",
      "[iter=16601]  loss = 0.2415\n",
      "[iter=16701]  loss = 0.2415\n",
      "[iter=16801]  loss = 0.2396\n",
      "[iter=16901]  loss = 0.2412\n",
      "[iter=17001]  loss = 0.2420\n",
      "[iter=17101]  loss = 0.2399\n",
      "[iter=17201]  loss = 0.2402\n",
      "[iter=17301]  loss = 0.2414\n",
      "[iter=17401]  loss = 0.2413\n",
      "[iter=17501]  loss = 0.2419\n",
      "[iter=17601]  loss = 0.2405\n",
      "[iter=17701]  loss = 0.2423\n",
      "[iter=17801]  loss = 0.2411\n",
      "[iter=17901]  loss = 0.2410\n",
      "[iter=18001]  loss = 0.2389\n",
      "[iter=18101]  loss = 0.2397\n",
      "[iter=18201]  loss = 0.2408\n",
      "[iter=18301]  loss = 0.2404\n",
      "[iter=18401]  loss = 0.2406\n",
      "[iter=18501]  loss = 0.2406\n",
      "[iter=18601]  loss = 0.2412\n",
      "[iter=18701]  loss = 0.2402\n",
      "[iter=18801]  loss = 0.2397\n",
      "[iter=18901]  loss = 0.2408\n",
      "[iter=19001]  loss = 0.2400\n",
      "[iter=19101]  loss = 0.2402\n",
      "[iter=19201]  loss = 0.2386\n",
      "[iter=19301]  loss = 0.2391\n",
      "[iter=19401]  loss = 0.2387\n",
      "[iter=19501]  loss = 0.2411\n",
      "[iter=19601]  loss = 0.2396\n",
      "[iter=19701]  loss = 0.2390\n",
      "[iter=19801]  loss = 0.2401\n",
      "[iter=19901]  loss = 0.2387\n",
      "[iter=20001]  loss = 0.2389\n",
      "[iter=20101]  loss = 0.2390\n",
      "[iter=20201]  loss = 0.2388\n",
      "[iter=20301]  loss = 0.2388\n",
      "[iter=20401]  loss = 0.2396\n",
      "[iter=20501]  loss = 0.2396\n",
      "[iter=20601]  loss = 0.2404\n",
      "[iter=20701]  loss = 0.2379\n",
      "[iter=20801]  loss = 0.2396\n",
      "[iter=20901]  loss = 0.2397\n",
      "[iter=21001]  loss = 0.2397\n",
      "[iter=21101]  loss = 0.2394\n",
      "[iter=21201]  loss = 0.2383\n",
      "[iter=21301]  loss = 0.2389\n",
      "[iter=21401]  loss = 0.2412\n",
      "[iter=21501]  loss = 0.2387\n",
      "[iter=21601]  loss = 0.2393\n",
      "[iter=21701]  loss = 0.2400\n",
      "[iter=21801]  loss = 0.2382\n",
      "[iter=21901]  loss = 0.2387\n",
      "[iter=22001]  loss = 0.2399\n",
      "[iter=22101]  loss = 0.2412\n",
      "[iter=22201]  loss = 0.2387\n",
      "[iter=22301]  loss = 0.2385\n",
      "[iter=22401]  loss = 0.2412\n",
      "[iter=22501]  loss = 0.2380\n",
      "[iter=22601]  loss = 0.2399\n",
      "[iter=22701]  loss = 0.2369\n",
      "[iter=22801]  loss = 0.2387\n",
      "[iter=22901]  loss = 0.2373\n",
      "[iter=23001]  loss = 0.2402\n",
      "[iter=23101]  loss = 0.2387\n",
      "[iter=23201]  loss = 0.2384\n",
      "[iter=23301]  loss = 0.2385\n",
      "[iter=23401]  loss = 0.2393\n",
      "[iter=23501]  loss = 0.2402\n",
      "[iter=23601]  loss = 0.2379\n",
      "[iter=23701]  loss = 0.2404\n",
      "[iter=23801]  loss = 0.2397\n",
      "[iter=23901]  loss = 0.2394\n",
      "[iter=24001]  loss = 0.2383\n",
      "[iter=24101]  loss = 0.2396\n",
      "[iter=24201]  loss = 0.2379\n",
      "[iter=24301]  loss = 0.2382\n",
      "[iter=24401]  loss = 0.2376\n",
      "[iter=24501]  loss = 0.2382\n",
      "[iter=24601]  loss = 0.2370\n",
      "[iter=24701]  loss = 0.2404\n",
      "[iter=24801]  loss = 0.2372\n",
      "[iter=24901]  loss = 0.2402\n",
      "[iter=25001]  loss = 0.2387\n",
      "[iter=25101]  loss = 0.2369\n",
      "[iter=25201]  loss = 0.2394\n",
      "[iter=25301]  loss = 0.2382\n",
      "[iter=25401]  loss = 0.2382\n",
      "[iter=25501]  loss = 0.2387\n",
      "[iter=25601]  loss = 0.2387\n",
      "[iter=25701]  loss = 0.2390\n",
      "[iter=25801]  loss = 0.2372\n",
      "[iter=25901]  loss = 0.2371\n",
      "[iter=26001]  loss = 0.2368\n",
      "[iter=26101]  loss = 0.2365\n",
      "[iter=26201]  loss = 0.2394\n",
      "[iter=26301]  loss = 0.2394\n",
      "[iter=26401]  loss = 0.2388\n",
      "[iter=26501]  loss = 0.2382\n",
      "[iter=26601]  loss = 0.2377\n",
      "[iter=26701]  loss = 0.2377\n",
      "[iter=26801]  loss = 0.2396\n",
      "[iter=26901]  loss = 0.2379\n",
      "[iter=27001]  loss = 0.2377\n",
      "[iter=27101]  loss = 0.2388\n",
      "[iter=27201]  loss = 0.2384\n",
      "[iter=27301]  loss = 0.2391\n",
      "[iter=27401]  loss = 0.2381\n",
      "[iter=27501]  loss = 0.2363\n",
      "[iter=27601]  loss = 0.2378\n",
      "[iter=27701]  loss = 0.2373\n",
      "[iter=27801]  loss = 0.2375\n",
      "[iter=27901]  loss = 0.2376\n",
      "[iter=28001]  loss = 0.2376\n",
      "[iter=28101]  loss = 0.2377\n",
      "[iter=28201]  loss = 0.2363\n",
      "[iter=28301]  loss = 0.2378\n",
      "[iter=28401]  loss = 0.2367\n",
      "[iter=28501]  loss = 0.2386\n",
      "[iter=28601]  loss = 0.2369\n",
      "[iter=28701]  loss = 0.2375\n",
      "[iter=28801]  loss = 0.2371\n",
      "[iter=28901]  loss = 0.2373\n",
      "[iter=29001]  loss = 0.2379\n",
      "[iter=29101]  loss = 0.2374\n",
      "[iter=29201]  loss = 0.2384\n",
      "[iter=29301]  loss = 0.2365\n",
      "[iter=29401]  loss = 0.2355\n",
      "[iter=29501]  loss = 0.2366\n",
      "[iter=29601]  loss = 0.2378\n",
      "[iter=29701]  loss = 0.2362\n",
      "[iter=29801]  loss = 0.2351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter=29901]  loss = 0.2369\n",
      "[iter=30001]  loss = 0.2347\n",
      "[iter=30101]  loss = 0.2364\n",
      "[iter=30201]  loss = 0.2369\n",
      "[iter=30301]  loss = 0.2363\n",
      "[iter=30401]  loss = 0.2349\n",
      "[iter=30501]  loss = 0.2372\n",
      "[iter=30601]  loss = 0.2379\n",
      "[iter=30701]  loss = 0.2377\n",
      "[iter=30801]  loss = 0.2349\n",
      "[iter=30901]  loss = 0.2363\n",
      "[iter=31001]  loss = 0.2369\n",
      "[iter=31101]  loss = 0.2376\n",
      "[iter=31201]  loss = 0.2370\n",
      "[iter=31301]  loss = 0.2375\n",
      "[iter=31401]  loss = 0.2356\n",
      "[iter=31501]  loss = 0.2362\n",
      "[iter=31601]  loss = 0.2355\n",
      "[iter=31701]  loss = 0.2370\n",
      "[iter=31801]  loss = 0.2376\n",
      "[iter=31901]  loss = 0.2356\n",
      "[iter=32001]  loss = 0.2371\n",
      "[iter=32101]  loss = 0.2362\n",
      "[iter=32201]  loss = 0.2370\n",
      "[iter=32301]  loss = 0.2356\n",
      "[iter=32401]  loss = 0.2363\n",
      "[iter=32501]  loss = 0.2348\n",
      "[iter=32601]  loss = 0.2372\n",
      "[iter=32701]  loss = 0.2370\n",
      "[iter=32801]  loss = 0.2358\n",
      "[iter=32901]  loss = 0.2351\n",
      "[iter=33001]  loss = 0.2345\n",
      "[iter=33101]  loss = 0.2371\n",
      "[iter=33201]  loss = 0.2341\n",
      "[iter=33301]  loss = 0.2359\n",
      "[iter=33401]  loss = 0.2343\n",
      "[iter=33501]  loss = 0.2339\n",
      "[iter=33601]  loss = 0.2347\n",
      "[iter=33701]  loss = 0.2359\n",
      "[iter=33801]  loss = 0.2366\n",
      "[iter=33901]  loss = 0.2355\n",
      "[iter=34001]  loss = 0.2353\n",
      "[iter=34101]  loss = 0.2348\n",
      "[iter=34201]  loss = 0.2368\n",
      "[iter=34301]  loss = 0.2342\n",
      "[iter=34401]  loss = 0.2350\n",
      "[iter=34501]  loss = 0.2334\n",
      "[iter=34601]  loss = 0.2350\n",
      "[iter=34701]  loss = 0.2374\n",
      "[iter=34801]  loss = 0.2365\n",
      "[iter=34901]  loss = 0.2326\n",
      "[iter=35001]  loss = 0.2349\n",
      "[iter=35101]  loss = 0.2351\n",
      "[iter=35201]  loss = 0.2325\n",
      "[iter=35301]  loss = 0.2341\n",
      "[iter=35401]  loss = 0.2341\n",
      "[iter=35501]  loss = 0.2347\n",
      "[iter=35601]  loss = 0.2341\n",
      "[iter=35701]  loss = 0.2351\n",
      "[iter=35801]  loss = 0.2348\n",
      "[iter=35901]  loss = 0.2353\n",
      "[iter=36001]  loss = 0.2341\n",
      "[iter=36101]  loss = 0.2358\n",
      "[iter=36201]  loss = 0.2338\n",
      "[iter=36301]  loss = 0.2350\n",
      "[iter=36401]  loss = 0.2354\n",
      "[iter=36501]  loss = 0.2343\n",
      "[iter=36601]  loss = 0.2350\n",
      "[iter=36701]  loss = 0.2349\n",
      "[iter=36801]  loss = 0.2347\n",
      "[iter=36901]  loss = 0.2339\n",
      "[iter=37001]  loss = 0.2337\n",
      "[iter=37101]  loss = 0.2335\n",
      "[iter=37201]  loss = 0.2337\n",
      "[iter=37301]  loss = 0.2336\n",
      "[iter=37401]  loss = 0.2343\n",
      "[iter=37501]  loss = 0.2355\n",
      "[iter=37601]  loss = 0.2332\n",
      "[iter=37701]  loss = 0.2349\n",
      "[iter=37801]  loss = 0.2332\n",
      "[iter=37901]  loss = 0.2359\n",
      "[iter=38001]  loss = 0.2355\n",
      "[iter=38101]  loss = 0.2334\n",
      "[iter=38201]  loss = 0.2354\n",
      "[iter=38301]  loss = 0.2348\n",
      "[iter=38401]  loss = 0.2344\n",
      "[iter=38501]  loss = 0.2344\n",
      "[iter=38601]  loss = 0.2347\n",
      "[iter=38701]  loss = 0.2344\n",
      "[iter=38801]  loss = 0.2354\n",
      "[iter=38901]  loss = 0.2342\n",
      "[iter=39001]  loss = 0.2347\n",
      "[iter=39101]  loss = 0.2324\n",
      "[iter=39201]  loss = 0.2348\n",
      "[iter=39301]  loss = 0.2331\n",
      "[iter=39401]  loss = 0.2333\n",
      "[iter=39501]  loss = 0.2334\n",
      "[iter=39601]  loss = 0.2340\n",
      "[iter=39701]  loss = 0.2341\n",
      "[iter=39801]  loss = 0.2324\n",
      "[iter=39901]  loss = 0.2329\n",
      "[iter=1]  loss = 0.0016\n",
      "[iter=101]  loss = 0.2340\n",
      "[iter=201]  loss = 0.2244\n",
      "[iter=301]  loss = 0.2211\n",
      "[iter=401]  loss = 0.2208\n",
      "[iter=501]  loss = 0.2192\n",
      "[iter=601]  loss = 0.2220\n",
      "[iter=701]  loss = 0.2218\n",
      "[iter=801]  loss = 0.2217\n",
      "[iter=901]  loss = 0.2214\n",
      "[iter=1001]  loss = 0.2198\n",
      "[iter=1101]  loss = 0.2215\n",
      "[iter=1201]  loss = 0.2196\n",
      "[iter=1301]  loss = 0.2241\n",
      "[iter=1401]  loss = 0.2227\n",
      "[iter=1501]  loss = 0.2203\n",
      "[iter=1601]  loss = 0.2212\n",
      "[iter=1701]  loss = 0.2193\n",
      "[iter=1801]  loss = 0.2196\n",
      "[iter=1901]  loss = 0.2182\n",
      "[iter=2001]  loss = 0.2189\n",
      "[iter=2101]  loss = 0.2187\n",
      "[iter=2201]  loss = 0.2184\n",
      "[iter=2301]  loss = 0.2194\n",
      "[iter=2401]  loss = 0.2209\n",
      "[iter=2501]  loss = 0.2217\n",
      "[iter=2601]  loss = 0.2189\n",
      "[iter=2701]  loss = 0.2179\n",
      "[iter=2801]  loss = 0.2213\n",
      "[iter=2901]  loss = 0.2173\n",
      "[iter=3001]  loss = 0.2207\n",
      "[iter=3101]  loss = 0.2151\n",
      "[iter=3201]  loss = 0.2163\n",
      "[iter=3301]  loss = 0.2160\n",
      "[iter=3401]  loss = 0.2167\n",
      "[iter=3501]  loss = 0.2191\n",
      "[iter=3601]  loss = 0.2155\n",
      "[iter=3701]  loss = 0.2189\n",
      "[iter=3801]  loss = 0.2146\n",
      "[iter=3901]  loss = 0.2161\n",
      "[iter=4001]  loss = 0.2151\n",
      "[iter=4101]  loss = 0.2135\n",
      "[iter=4201]  loss = 0.2145\n",
      "[iter=4301]  loss = 0.2142\n",
      "[iter=4401]  loss = 0.2129\n",
      "[iter=4501]  loss = 0.2098\n",
      "[iter=4601]  loss = 0.2106\n",
      "[iter=4701]  loss = 0.2116\n",
      "[iter=4801]  loss = 0.2109\n",
      "[iter=4901]  loss = 0.2134\n",
      "[iter=5001]  loss = 0.2131\n",
      "[iter=5101]  loss = 0.2169\n",
      "[iter=5201]  loss = 0.2154\n",
      "[iter=5301]  loss = 0.2109\n",
      "[iter=5401]  loss = 0.2106\n",
      "[iter=5501]  loss = 0.2146\n",
      "[iter=5601]  loss = 0.2121\n",
      "[iter=5701]  loss = 0.2104\n",
      "[iter=5801]  loss = 0.2102\n",
      "[iter=5901]  loss = 0.2113\n",
      "[iter=6001]  loss = 0.2106\n",
      "[iter=6101]  loss = 0.2101\n",
      "[iter=6201]  loss = 0.2100\n",
      "[iter=6301]  loss = 0.2103\n",
      "[iter=6401]  loss = 0.2109\n",
      "[iter=6501]  loss = 0.2120\n",
      "[iter=6601]  loss = 0.2087\n",
      "[iter=6701]  loss = 0.2078\n",
      "[iter=6801]  loss = 0.2065\n",
      "[iter=6901]  loss = 0.2049\n",
      "[iter=7001]  loss = 0.2069\n",
      "[iter=7101]  loss = 0.2080\n",
      "[iter=7201]  loss = 0.2070\n",
      "[iter=7301]  loss = 0.2044\n",
      "[iter=7401]  loss = 0.2078\n",
      "[iter=7501]  loss = 0.2089\n",
      "[iter=7601]  loss = 0.2056\n",
      "[iter=7701]  loss = 0.2036\n",
      "[iter=7801]  loss = 0.2051\n",
      "[iter=7901]  loss = 0.2059\n",
      "[iter=8001]  loss = 0.2084\n",
      "[iter=8101]  loss = 0.2085\n",
      "[iter=8201]  loss = 0.2078\n",
      "[iter=8301]  loss = 0.2071\n",
      "[iter=8401]  loss = 0.2036\n",
      "[iter=8501]  loss = 0.2084\n",
      "[iter=8601]  loss = 0.2071\n",
      "[iter=8701]  loss = 0.2068\n",
      "[iter=8801]  loss = 0.2052\n",
      "[iter=8901]  loss = 0.2047\n",
      "[iter=9001]  loss = 0.2054\n",
      "[iter=9101]  loss = 0.2026\n",
      "[iter=9201]  loss = 0.2027\n",
      "[iter=9301]  loss = 0.2035\n",
      "[iter=9401]  loss = 0.2051\n",
      "[iter=9501]  loss = 0.2031\n",
      "[iter=9601]  loss = 0.2037\n",
      "[iter=9701]  loss = 0.2047\n",
      "[iter=9801]  loss = 0.2037\n",
      "[iter=9901]  loss = 0.2011\n",
      "[iter=10001]  loss = 0.2037\n",
      "[iter=10101]  loss = 0.2042\n",
      "[iter=10201]  loss = 0.2002\n",
      "[iter=10301]  loss = 0.2043\n",
      "[iter=10401]  loss = 0.2034\n",
      "[iter=10501]  loss = 0.2071\n",
      "[iter=10601]  loss = 0.2046\n",
      "[iter=10701]  loss = 0.1997\n",
      "[iter=10801]  loss = 0.2029\n",
      "[iter=10901]  loss = 0.2043\n",
      "[iter=11001]  loss = 0.2007\n",
      "[iter=11101]  loss = 0.2026\n",
      "[iter=11201]  loss = 0.2021\n",
      "[iter=11301]  loss = 0.2011\n",
      "[iter=11401]  loss = 0.1987\n",
      "[iter=11501]  loss = 0.2006\n",
      "[iter=11601]  loss = 0.2019\n",
      "[iter=11701]  loss = 0.2022\n",
      "[iter=11801]  loss = 0.1983\n",
      "[iter=11901]  loss = 0.1960\n",
      "[iter=12001]  loss = 0.1966\n",
      "[iter=12101]  loss = 0.1983\n",
      "[iter=12201]  loss = 0.1987\n",
      "[iter=12301]  loss = 0.2003\n",
      "[iter=12401]  loss = 0.1972\n",
      "[iter=12501]  loss = 0.1993\n",
      "[iter=12601]  loss = 0.1965\n",
      "[iter=12701]  loss = 0.1982\n",
      "[iter=12801]  loss = 0.1972\n",
      "[iter=12901]  loss = 0.2007\n",
      "[iter=13001]  loss = 0.1953\n",
      "[iter=13101]  loss = 0.1978\n",
      "[iter=13201]  loss = 0.1967\n",
      "[iter=13301]  loss = 0.1974\n",
      "[iter=13401]  loss = 0.2015\n",
      "[iter=13501]  loss = 0.1970\n",
      "[iter=13601]  loss = 0.1996\n",
      "[iter=13701]  loss = 0.1986\n",
      "[iter=13801]  loss = 0.1998\n",
      "[iter=13901]  loss = 0.1957\n",
      "[iter=14001]  loss = 0.1972\n",
      "[iter=14101]  loss = 0.2001\n",
      "[iter=14201]  loss = 0.1938\n",
      "[iter=14301]  loss = 0.2005\n",
      "[iter=14401]  loss = 0.1971\n",
      "[iter=14501]  loss = 0.1954\n",
      "[iter=14601]  loss = 0.1997\n",
      "[iter=14701]  loss = 0.1998\n",
      "[iter=14801]  loss = 0.1942\n",
      "[iter=14901]  loss = 0.1972\n",
      "[iter=15001]  loss = 0.1970\n",
      "[iter=15101]  loss = 0.1961\n",
      "[iter=15201]  loss = 0.1964\n",
      "[iter=15301]  loss = 0.1939\n",
      "[iter=15401]  loss = 0.1934\n",
      "[iter=15501]  loss = 0.1941\n",
      "[iter=15601]  loss = 0.1968\n",
      "[iter=15701]  loss = 0.1953\n",
      "[iter=15801]  loss = 0.1954\n",
      "[iter=15901]  loss = 0.1917\n",
      "[iter=16001]  loss = 0.1937\n",
      "[iter=16101]  loss = 0.1965\n",
      "[iter=16201]  loss = 0.1954\n",
      "[iter=16301]  loss = 0.1946\n",
      "[iter=16401]  loss = 0.1990\n",
      "[iter=16501]  loss = 0.1959\n",
      "[iter=16601]  loss = 0.1930\n",
      "[iter=16701]  loss = 0.1984\n",
      "[iter=16801]  loss = 0.1958\n",
      "[iter=16901]  loss = 0.1933\n",
      "[iter=17001]  loss = 0.1969\n",
      "[iter=17101]  loss = 0.1938\n",
      "[iter=17201]  loss = 0.1924\n",
      "[iter=17301]  loss = 0.1946\n",
      "[iter=17401]  loss = 0.1956\n",
      "[iter=17501]  loss = 0.1933\n",
      "[iter=17601]  loss = 0.1964\n",
      "[iter=17701]  loss = 0.1920\n",
      "[iter=17801]  loss = 0.1940\n",
      "[iter=17901]  loss = 0.1910\n",
      "[iter=18001]  loss = 0.1963\n",
      "[iter=18101]  loss = 0.1951\n",
      "[iter=18201]  loss = 0.1935\n",
      "[iter=18301]  loss = 0.1939\n",
      "[iter=18401]  loss = 0.1941\n",
      "[iter=18501]  loss = 0.1908\n",
      "[iter=18601]  loss = 0.1916\n",
      "[iter=18701]  loss = 0.1889\n",
      "[iter=18801]  loss = 0.1928\n",
      "[iter=18901]  loss = 0.1874\n",
      "[iter=19001]  loss = 0.1925\n",
      "[iter=19101]  loss = 0.1903\n",
      "[iter=19201]  loss = 0.1936\n",
      "[iter=19301]  loss = 0.1918\n",
      "[iter=19401]  loss = 0.1912\n",
      "[iter=19501]  loss = 0.1923\n",
      "[iter=19601]  loss = 0.1875\n",
      "[iter=19701]  loss = 0.1920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter=19801]  loss = 0.1937\n",
      "[iter=19901]  loss = 0.1897\n",
      "[iter=20001]  loss = 0.1943\n",
      "[iter=20101]  loss = 0.1892\n",
      "[iter=20201]  loss = 0.1888\n",
      "[iter=20301]  loss = 0.1867\n",
      "[iter=20401]  loss = 0.1887\n",
      "[iter=20501]  loss = 0.1912\n",
      "[iter=20601]  loss = 0.1884\n",
      "[iter=20701]  loss = 0.1889\n",
      "[iter=20801]  loss = 0.1906\n",
      "[iter=20901]  loss = 0.1875\n",
      "[iter=21001]  loss = 0.1922\n",
      "[iter=21101]  loss = 0.1870\n",
      "[iter=21201]  loss = 0.1855\n",
      "[iter=21301]  loss = 0.1886\n",
      "[iter=21401]  loss = 0.1917\n",
      "[iter=21501]  loss = 0.1855\n",
      "[iter=21601]  loss = 0.1895\n",
      "[iter=21701]  loss = 0.1929\n",
      "[iter=21801]  loss = 0.1876\n",
      "[iter=21901]  loss = 0.1858\n",
      "[iter=22001]  loss = 0.1850\n",
      "[iter=22101]  loss = 0.1818\n",
      "[iter=22201]  loss = 0.1846\n",
      "[iter=22301]  loss = 0.1820\n",
      "[iter=22401]  loss = 0.1855\n",
      "[iter=22501]  loss = 0.1876\n",
      "[iter=22601]  loss = 0.1896\n",
      "[iter=22701]  loss = 0.1900\n",
      "[iter=22801]  loss = 0.1854\n",
      "[iter=22901]  loss = 0.1872\n",
      "[iter=23001]  loss = 0.1850\n",
      "[iter=23101]  loss = 0.1879\n",
      "[iter=23201]  loss = 0.1892\n",
      "[iter=23301]  loss = 0.1834\n",
      "[iter=23401]  loss = 0.1854\n",
      "[iter=23501]  loss = 0.1845\n",
      "[iter=23601]  loss = 0.1840\n",
      "[iter=23701]  loss = 0.1828\n",
      "[iter=23801]  loss = 0.1916\n",
      "[iter=23901]  loss = 0.1845\n",
      "[iter=24001]  loss = 0.1843\n",
      "[iter=24101]  loss = 0.1870\n",
      "[iter=24201]  loss = 0.1809\n",
      "[iter=24301]  loss = 0.1859\n",
      "[iter=24401]  loss = 0.1846\n",
      "[iter=24501]  loss = 0.1872\n",
      "[iter=24601]  loss = 0.1852\n",
      "[iter=24701]  loss = 0.1858\n",
      "[iter=24801]  loss = 0.1833\n",
      "[iter=24901]  loss = 0.1810\n",
      "[iter=25001]  loss = 0.1833\n",
      "[iter=25101]  loss = 0.1887\n",
      "[iter=25201]  loss = 0.1840\n",
      "[iter=25301]  loss = 0.1829\n",
      "[iter=25401]  loss = 0.1865\n",
      "[iter=25501]  loss = 0.1849\n",
      "[iter=25601]  loss = 0.1837\n",
      "[iter=25701]  loss = 0.1828\n",
      "[iter=25801]  loss = 0.1776\n",
      "[iter=25901]  loss = 0.1793\n",
      "[iter=26001]  loss = 0.1825\n",
      "[iter=26101]  loss = 0.1851\n",
      "[iter=26201]  loss = 0.1855\n",
      "[iter=26301]  loss = 0.1809\n",
      "[iter=26401]  loss = 0.1793\n",
      "[iter=26501]  loss = 0.1878\n",
      "[iter=26601]  loss = 0.1840\n",
      "[iter=26701]  loss = 0.1810\n",
      "[iter=26801]  loss = 0.1862\n",
      "[iter=26901]  loss = 0.1828\n",
      "[iter=27001]  loss = 0.1778\n",
      "[iter=27101]  loss = 0.1837\n",
      "[iter=27201]  loss = 0.1830\n",
      "[iter=27301]  loss = 0.1829\n",
      "[iter=27401]  loss = 0.1790\n",
      "[iter=27501]  loss = 0.1809\n",
      "[iter=27601]  loss = 0.1861\n",
      "[iter=27701]  loss = 0.1824\n",
      "[iter=27801]  loss = 0.1820\n",
      "[iter=27901]  loss = 0.1823\n",
      "[iter=28001]  loss = 0.1845\n",
      "[iter=28101]  loss = 0.1808\n",
      "[iter=28201]  loss = 0.1759\n",
      "[iter=28301]  loss = 0.1789\n",
      "[iter=28401]  loss = 0.1868\n",
      "[iter=28501]  loss = 0.1750\n",
      "[iter=28601]  loss = 0.1845\n",
      "[iter=28701]  loss = 0.1764\n",
      "[iter=28801]  loss = 0.1789\n",
      "[iter=28901]  loss = 0.1824\n",
      "[iter=29001]  loss = 0.1811\n",
      "[iter=29101]  loss = 0.1811\n",
      "[iter=29201]  loss = 0.1780\n",
      "[iter=29301]  loss = 0.1821\n",
      "[iter=29401]  loss = 0.1826\n",
      "[iter=29501]  loss = 0.1800\n",
      "[iter=29601]  loss = 0.1809\n",
      "[iter=29701]  loss = 0.1854\n",
      "[iter=29801]  loss = 0.1773\n",
      "[iter=29901]  loss = 0.1805\n",
      "[iter=30001]  loss = 0.1849\n",
      "[iter=30101]  loss = 0.1778\n",
      "[iter=30201]  loss = 0.1819\n",
      "[iter=30301]  loss = 0.1814\n",
      "[iter=30401]  loss = 0.1795\n",
      "[iter=30501]  loss = 0.1791\n",
      "[iter=30601]  loss = 0.1833\n",
      "[iter=30701]  loss = 0.1794\n",
      "[iter=30801]  loss = 0.1812\n",
      "[iter=30901]  loss = 0.1862\n",
      "[iter=31001]  loss = 0.1774\n",
      "[iter=31101]  loss = 0.1826\n",
      "[iter=31201]  loss = 0.1764\n",
      "[iter=31301]  loss = 0.1793\n",
      "[iter=31401]  loss = 0.1782\n",
      "[iter=31501]  loss = 0.1811\n",
      "[iter=31601]  loss = 0.1855\n",
      "[iter=31701]  loss = 0.1806\n",
      "[iter=31801]  loss = 0.1758\n",
      "[iter=31901]  loss = 0.1800\n",
      "[iter=32001]  loss = 0.1808\n",
      "[iter=32101]  loss = 0.1736\n",
      "[iter=32201]  loss = 0.1751\n",
      "[iter=32301]  loss = 0.1851\n",
      "[iter=32401]  loss = 0.1768\n",
      "[iter=32501]  loss = 0.1843\n",
      "[iter=32601]  loss = 0.1754\n",
      "[iter=32701]  loss = 0.1822\n",
      "[iter=32801]  loss = 0.1784\n",
      "[iter=32901]  loss = 0.1758\n",
      "[iter=33001]  loss = 0.1757\n",
      "[iter=33101]  loss = 0.1824\n",
      "[iter=33201]  loss = 0.1777\n",
      "[iter=33301]  loss = 0.1849\n",
      "[iter=33401]  loss = 0.1719\n",
      "[iter=33501]  loss = 0.1747\n",
      "[iter=33601]  loss = 0.1742\n",
      "[iter=33701]  loss = 0.1734\n",
      "[iter=33801]  loss = 0.1747\n",
      "[iter=33901]  loss = 0.1840\n",
      "[iter=34001]  loss = 0.1801\n",
      "[iter=34101]  loss = 0.1824\n",
      "[iter=34201]  loss = 0.1785\n",
      "[iter=34301]  loss = 0.1799\n",
      "[iter=34401]  loss = 0.1793\n",
      "[iter=34501]  loss = 0.1768\n",
      "[iter=34601]  loss = 0.1788\n",
      "[iter=34701]  loss = 0.1801\n",
      "[iter=34801]  loss = 0.1734\n",
      "[iter=34901]  loss = 0.1740\n",
      "[iter=35001]  loss = 0.1798\n",
      "[iter=35101]  loss = 0.1760\n",
      "[iter=35201]  loss = 0.1779\n",
      "[iter=35301]  loss = 0.1783\n",
      "[iter=35401]  loss = 0.1749\n",
      "[iter=35501]  loss = 0.1806\n",
      "[iter=35601]  loss = 0.1802\n",
      "[iter=35701]  loss = 0.1807\n",
      "[iter=35801]  loss = 0.1705\n",
      "[iter=35901]  loss = 0.1797\n",
      "[iter=36001]  loss = 0.1756\n",
      "[iter=36101]  loss = 0.1757\n",
      "[iter=36201]  loss = 0.1749\n",
      "[iter=36301]  loss = 0.1753\n",
      "[iter=36401]  loss = 0.1767\n",
      "[iter=36501]  loss = 0.1712\n",
      "[iter=36601]  loss = 0.1777\n",
      "[iter=36701]  loss = 0.1678\n",
      "[iter=36801]  loss = 0.1794\n",
      "[iter=36901]  loss = 0.1752\n",
      "[iter=37001]  loss = 0.1756\n",
      "[iter=37101]  loss = 0.1802\n",
      "[iter=37201]  loss = 0.1783\n",
      "[iter=37301]  loss = 0.1728\n",
      "[iter=37401]  loss = 0.1762\n",
      "[iter=37501]  loss = 0.1770\n",
      "[iter=37601]  loss = 0.1774\n",
      "[iter=37701]  loss = 0.1731\n",
      "[iter=37801]  loss = 0.1741\n",
      "[iter=37901]  loss = 0.1758\n",
      "[iter=38001]  loss = 0.1715\n",
      "[iter=38101]  loss = 0.1726\n",
      "[iter=38201]  loss = 0.1750\n",
      "[iter=38301]  loss = 0.1806\n",
      "[iter=38401]  loss = 0.1732\n",
      "[iter=38501]  loss = 0.1763\n",
      "[iter=38601]  loss = 0.1705\n",
      "[iter=38701]  loss = 0.1767\n",
      "[iter=38801]  loss = 0.1813\n",
      "[iter=38901]  loss = 0.1751\n",
      "[iter=39001]  loss = 0.1731\n",
      "[iter=39101]  loss = 0.1681\n",
      "[iter=39201]  loss = 0.1757\n",
      "[iter=39301]  loss = 0.1746\n",
      "[iter=39401]  loss = 0.1704\n",
      "[iter=39501]  loss = 0.1760\n",
      "[iter=39601]  loss = 0.1747\n",
      "[iter=39701]  loss = 0.1780\n",
      "[iter=39801]  loss = 0.1741\n",
      "[iter=39901]  loss = 0.1693\n",
      "[iter=1]  loss = 0.0030\n",
      "[iter=101]  loss = 0.2208\n",
      "[iter=201]  loss = 0.2175\n",
      "[iter=301]  loss = 0.2178\n",
      "[iter=401]  loss = 0.2218\n",
      "[iter=501]  loss = 0.2163\n",
      "[iter=601]  loss = 0.2216\n",
      "[iter=701]  loss = 0.2220\n",
      "[iter=801]  loss = 0.2176\n",
      "[iter=901]  loss = 0.2171\n",
      "[iter=1001]  loss = 0.2216\n",
      "[iter=1101]  loss = 0.2148\n",
      "[iter=1201]  loss = 0.2129\n",
      "[iter=1301]  loss = 0.2155\n",
      "[iter=1401]  loss = 0.2147\n",
      "[iter=1501]  loss = 0.2126\n",
      "[iter=1601]  loss = 0.2145\n",
      "[iter=1701]  loss = 0.2122\n",
      "[iter=1801]  loss = 0.2038\n",
      "[iter=1901]  loss = 0.2075\n",
      "[iter=2001]  loss = 0.2056\n",
      "[iter=2101]  loss = 0.2057\n",
      "[iter=2201]  loss = 0.2008\n",
      "[iter=2301]  loss = 0.2049\n",
      "[iter=2401]  loss = 0.2034\n",
      "[iter=2501]  loss = 0.2034\n",
      "[iter=2601]  loss = 0.2025\n",
      "[iter=2701]  loss = 0.2075\n",
      "[iter=2801]  loss = 0.2075\n",
      "[iter=2901]  loss = 0.2070\n",
      "[iter=3001]  loss = 0.2021\n",
      "[iter=3101]  loss = 0.2027\n",
      "[iter=3201]  loss = 0.2025\n",
      "[iter=3301]  loss = 0.2058\n",
      "[iter=3401]  loss = 0.2028\n",
      "[iter=3501]  loss = 0.1990\n",
      "[iter=3601]  loss = 0.1943\n",
      "[iter=3701]  loss = 0.1950\n",
      "[iter=3801]  loss = 0.1966\n",
      "[iter=3901]  loss = 0.2004\n",
      "[iter=4001]  loss = 0.1972\n",
      "[iter=4101]  loss = 0.2016\n",
      "[iter=4201]  loss = 0.1945\n",
      "[iter=4301]  loss = 0.1919\n",
      "[iter=4401]  loss = 0.1942\n",
      "[iter=4501]  loss = 0.1966\n",
      "[iter=4601]  loss = 0.1934\n",
      "[iter=4701]  loss = 0.1957\n",
      "[iter=4801]  loss = 0.1928\n",
      "[iter=4901]  loss = 0.1938\n",
      "[iter=5001]  loss = 0.1925\n",
      "[iter=5101]  loss = 0.1949\n",
      "[iter=5201]  loss = 0.1900\n",
      "[iter=5301]  loss = 0.1863\n",
      "[iter=5401]  loss = 0.1843\n",
      "[iter=5501]  loss = 0.1803\n",
      "[iter=5601]  loss = 0.1840\n",
      "[iter=5701]  loss = 0.1867\n",
      "[iter=5801]  loss = 0.1890\n",
      "[iter=5901]  loss = 0.1919\n",
      "[iter=6001]  loss = 0.1876\n",
      "[iter=6101]  loss = 0.1834\n",
      "[iter=6201]  loss = 0.1851\n",
      "[iter=6301]  loss = 0.1875\n",
      "[iter=6401]  loss = 0.1812\n",
      "[iter=6501]  loss = 0.1861\n",
      "[iter=6601]  loss = 0.1807\n",
      "[iter=6701]  loss = 0.1777\n",
      "[iter=6801]  loss = 0.1812\n",
      "[iter=6901]  loss = 0.1776\n",
      "[iter=7001]  loss = 0.1875\n",
      "[iter=7101]  loss = 0.1771\n",
      "[iter=7201]  loss = 0.1817\n",
      "[iter=7301]  loss = 0.1773\n",
      "[iter=7401]  loss = 0.1807\n",
      "[iter=7501]  loss = 0.1762\n",
      "[iter=7601]  loss = 0.1795\n",
      "[iter=7701]  loss = 0.1774\n",
      "[iter=7801]  loss = 0.1743\n",
      "[iter=7901]  loss = 0.1792\n",
      "[iter=8001]  loss = 0.1768\n",
      "[iter=8101]  loss = 0.1779\n",
      "[iter=8201]  loss = 0.1784\n",
      "[iter=8301]  loss = 0.1764\n",
      "[iter=8401]  loss = 0.1715\n",
      "[iter=8501]  loss = 0.1770\n",
      "[iter=8601]  loss = 0.1800\n",
      "[iter=8701]  loss = 0.1782\n",
      "[iter=8801]  loss = 0.1788\n",
      "[iter=8901]  loss = 0.1746\n",
      "[iter=9001]  loss = 0.1753\n",
      "[iter=9101]  loss = 0.1785\n",
      "[iter=9201]  loss = 0.1741\n",
      "[iter=9301]  loss = 0.1735\n",
      "[iter=9401]  loss = 0.1775\n",
      "[iter=9501]  loss = 0.1757\n",
      "[iter=9601]  loss = 0.1733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter=9701]  loss = 0.1668\n",
      "[iter=9801]  loss = 0.1714\n",
      "[iter=9901]  loss = 0.1683\n",
      "[iter=10001]  loss = 0.1703\n",
      "[iter=10101]  loss = 0.1667\n",
      "[iter=10201]  loss = 0.1684\n",
      "[iter=10301]  loss = 0.1685\n",
      "[iter=10401]  loss = 0.1701\n",
      "[iter=10501]  loss = 0.1706\n",
      "[iter=10601]  loss = 0.1719\n",
      "[iter=10701]  loss = 0.1692\n",
      "[iter=10801]  loss = 0.1698\n",
      "[iter=10901]  loss = 0.1696\n",
      "[iter=11001]  loss = 0.1634\n",
      "[iter=11101]  loss = 0.1749\n",
      "[iter=11201]  loss = 0.1693\n",
      "[iter=11301]  loss = 0.1704\n",
      "[iter=11401]  loss = 0.1697\n",
      "[iter=11501]  loss = 0.1730\n",
      "[iter=11601]  loss = 0.1710\n",
      "[iter=11701]  loss = 0.1667\n",
      "[iter=11801]  loss = 0.1682\n",
      "[iter=11901]  loss = 0.1669\n",
      "[iter=12001]  loss = 0.1671\n",
      "[iter=12101]  loss = 0.1616\n",
      "[iter=12201]  loss = 0.1706\n",
      "[iter=12301]  loss = 0.1676\n",
      "[iter=12401]  loss = 0.1709\n",
      "[iter=12501]  loss = 0.1727\n",
      "[iter=12601]  loss = 0.1723\n",
      "[iter=12701]  loss = 0.1672\n",
      "[iter=12801]  loss = 0.1622\n",
      "[iter=12901]  loss = 0.1688\n",
      "[iter=13001]  loss = 0.1649\n",
      "[iter=13101]  loss = 0.1741\n",
      "[iter=13201]  loss = 0.1650\n",
      "[iter=13301]  loss = 0.1644\n",
      "[iter=13401]  loss = 0.1645\n",
      "[iter=13501]  loss = 0.1658\n",
      "[iter=13601]  loss = 0.1643\n",
      "[iter=13701]  loss = 0.1620\n",
      "[iter=13801]  loss = 0.1642\n",
      "[iter=13901]  loss = 0.1717\n",
      "[iter=14001]  loss = 0.1626\n",
      "[iter=14101]  loss = 0.1641\n",
      "[iter=14201]  loss = 0.1668\n",
      "[iter=14301]  loss = 0.1665\n",
      "[iter=14401]  loss = 0.1665\n",
      "[iter=14501]  loss = 0.1604\n",
      "[iter=14601]  loss = 0.1551\n",
      "[iter=14701]  loss = 0.1681\n",
      "[iter=14801]  loss = 0.1628\n",
      "[iter=14901]  loss = 0.1620\n",
      "[iter=15001]  loss = 0.1623\n",
      "[iter=15101]  loss = 0.1666\n",
      "[iter=15201]  loss = 0.1629\n",
      "[iter=15301]  loss = 0.1677\n",
      "[iter=15401]  loss = 0.1673\n",
      "[iter=15501]  loss = 0.1612\n",
      "[iter=15601]  loss = 0.1584\n",
      "[iter=15701]  loss = 0.1611\n",
      "[iter=15801]  loss = 0.1622\n",
      "[iter=15901]  loss = 0.1630\n",
      "[iter=16001]  loss = 0.1609\n",
      "[iter=16101]  loss = 0.1637\n",
      "[iter=16201]  loss = 0.1640\n",
      "[iter=16301]  loss = 0.1593\n",
      "[iter=16401]  loss = 0.1596\n",
      "[iter=16501]  loss = 0.1556\n",
      "[iter=16601]  loss = 0.1621\n",
      "[iter=16701]  loss = 0.1608\n",
      "[iter=16801]  loss = 0.1606\n",
      "[iter=16901]  loss = 0.1579\n",
      "[iter=17001]  loss = 0.1563\n",
      "[iter=17101]  loss = 0.1543\n",
      "[iter=17201]  loss = 0.1608\n",
      "[iter=17301]  loss = 0.1513\n",
      "[iter=17401]  loss = 0.1591\n",
      "[iter=17501]  loss = 0.1558\n",
      "[iter=17601]  loss = 0.1551\n",
      "[iter=17701]  loss = 0.1624\n",
      "[iter=17801]  loss = 0.1593\n",
      "[iter=17901]  loss = 0.1630\n",
      "[iter=18001]  loss = 0.1560\n",
      "[iter=18101]  loss = 0.1613\n",
      "[iter=18201]  loss = 0.1676\n",
      "[iter=18301]  loss = 0.1607\n",
      "[iter=18401]  loss = 0.1632\n",
      "[iter=18501]  loss = 0.1531\n",
      "[iter=18601]  loss = 0.1604\n",
      "[iter=18701]  loss = 0.1595\n",
      "[iter=18801]  loss = 0.1666\n",
      "[iter=18901]  loss = 0.1608\n",
      "[iter=19001]  loss = 0.1633\n",
      "[iter=19101]  loss = 0.1657\n",
      "[iter=19201]  loss = 0.1602\n",
      "[iter=19301]  loss = 0.1643\n",
      "[iter=19401]  loss = 0.1739\n",
      "[iter=19501]  loss = 0.1631\n",
      "[iter=19601]  loss = 0.1643\n",
      "[iter=19701]  loss = 0.1491\n",
      "[iter=19801]  loss = 0.1540\n",
      "[iter=19901]  loss = 0.1642\n",
      "[iter=20001]  loss = 0.1606\n",
      "[iter=20101]  loss = 0.1620\n",
      "[iter=20201]  loss = 0.1600\n",
      "[iter=20301]  loss = 0.1541\n",
      "[iter=20401]  loss = 0.1596\n",
      "[iter=20501]  loss = 0.1603\n",
      "[iter=20601]  loss = 0.1580\n",
      "[iter=20701]  loss = 0.1575\n",
      "[iter=20801]  loss = 0.1575\n",
      "[iter=20901]  loss = 0.1589\n",
      "[iter=21001]  loss = 0.1624\n",
      "[iter=21101]  loss = 0.1589\n",
      "[iter=21201]  loss = 0.1536\n",
      "[iter=21301]  loss = 0.1534\n",
      "[iter=21401]  loss = 0.1617\n",
      "[iter=21501]  loss = 0.1603\n",
      "[iter=21601]  loss = 0.1556\n",
      "[iter=21701]  loss = 0.1555\n",
      "[iter=21801]  loss = 0.1518\n",
      "[iter=21901]  loss = 0.1587\n",
      "[iter=22001]  loss = 0.1551\n",
      "[iter=22101]  loss = 0.1617\n",
      "[iter=22201]  loss = 0.1646\n",
      "[iter=22301]  loss = 0.1592\n",
      "[iter=22401]  loss = 0.1555\n",
      "[iter=22501]  loss = 0.1561\n",
      "[iter=22601]  loss = 0.1549\n",
      "[iter=22701]  loss = 0.1533\n",
      "[iter=22801]  loss = 0.1526\n",
      "[iter=22901]  loss = 0.1590\n",
      "[iter=23001]  loss = 0.1564\n",
      "[iter=23101]  loss = 0.1618\n",
      "[iter=23201]  loss = 0.1553\n",
      "[iter=23301]  loss = 0.1582\n",
      "[iter=23401]  loss = 0.1625\n",
      "[iter=23501]  loss = 0.1548\n",
      "[iter=23601]  loss = 0.1557\n",
      "[iter=23701]  loss = 0.1484\n",
      "[iter=23801]  loss = 0.1456\n",
      "[iter=23901]  loss = 0.1639\n",
      "[iter=24001]  loss = 0.1575\n",
      "[iter=24101]  loss = 0.1525\n",
      "[iter=24201]  loss = 0.1536\n",
      "[iter=24301]  loss = 0.1587\n",
      "[iter=24401]  loss = 0.1611\n",
      "[iter=24501]  loss = 0.1605\n",
      "[iter=24601]  loss = 0.1528\n",
      "[iter=24701]  loss = 0.1532\n",
      "[iter=24801]  loss = 0.1613\n",
      "[iter=24901]  loss = 0.1581\n",
      "[iter=25001]  loss = 0.1572\n",
      "[iter=25101]  loss = 0.1593\n",
      "[iter=25201]  loss = 0.1544\n",
      "[iter=25301]  loss = 0.1614\n",
      "[iter=25401]  loss = 0.1635\n",
      "[iter=25501]  loss = 0.1498\n",
      "[iter=25601]  loss = 0.1517\n",
      "[iter=25701]  loss = 0.1538\n",
      "[iter=25801]  loss = 0.1464\n",
      "[iter=25901]  loss = 0.1508\n",
      "[iter=26001]  loss = 0.1538\n",
      "[iter=26101]  loss = 0.1541\n",
      "[iter=26201]  loss = 0.1639\n",
      "[iter=26301]  loss = 0.1547\n",
      "[iter=26401]  loss = 0.1637\n",
      "[iter=26501]  loss = 0.1529\n",
      "[iter=26601]  loss = 0.1523\n",
      "[iter=26701]  loss = 0.1518\n",
      "[iter=26801]  loss = 0.1592\n",
      "[iter=26901]  loss = 0.1644\n",
      "[iter=27001]  loss = 0.1563\n",
      "[iter=27101]  loss = 0.1476\n",
      "[iter=27201]  loss = 0.1520\n",
      "[iter=27301]  loss = 0.1591\n",
      "[iter=27401]  loss = 0.1536\n",
      "[iter=27501]  loss = 0.1467\n",
      "[iter=27601]  loss = 0.1577\n",
      "[iter=27701]  loss = 0.1478\n",
      "[iter=27801]  loss = 0.1543\n",
      "[iter=27901]  loss = 0.1612\n",
      "[iter=28001]  loss = 0.1549\n",
      "[iter=28101]  loss = 0.1612\n",
      "[iter=28201]  loss = 0.1599\n",
      "[iter=28301]  loss = 0.1544\n",
      "[iter=28401]  loss = 0.1654\n",
      "[iter=28501]  loss = 0.1621\n",
      "[iter=28601]  loss = 0.1549\n",
      "[iter=28701]  loss = 0.1525\n",
      "[iter=28801]  loss = 0.1623\n",
      "[iter=28901]  loss = 0.1547\n",
      "[iter=29001]  loss = 0.1535\n",
      "[iter=29101]  loss = 0.1632\n",
      "[iter=29201]  loss = 0.1612\n",
      "[iter=29301]  loss = 0.1544\n",
      "[iter=29401]  loss = 0.1478\n",
      "[iter=29501]  loss = 0.1509\n",
      "[iter=29601]  loss = 0.1570\n",
      "[iter=29701]  loss = 0.1546\n",
      "[iter=29801]  loss = 0.1638\n",
      "[iter=29901]  loss = 0.1568\n",
      "[iter=30001]  loss = 0.1627\n",
      "[iter=30101]  loss = 0.1547\n",
      "[iter=30201]  loss = 0.1507\n",
      "[iter=30301]  loss = 0.1550\n",
      "[iter=30401]  loss = 0.1545\n",
      "[iter=30501]  loss = 0.1477\n",
      "[iter=30601]  loss = 0.1587\n",
      "[iter=30701]  loss = 0.1555\n",
      "[iter=30801]  loss = 0.1564\n",
      "[iter=30901]  loss = 0.1514\n",
      "[iter=31001]  loss = 0.1568\n",
      "[iter=31101]  loss = 0.1615\n",
      "[iter=31201]  loss = 0.1555\n",
      "[iter=31301]  loss = 0.1674\n",
      "[iter=31401]  loss = 0.1619\n",
      "[iter=31501]  loss = 0.1566\n",
      "[iter=31601]  loss = 0.1620\n",
      "[iter=31701]  loss = 0.1646\n",
      "[iter=31801]  loss = 0.1626\n",
      "[iter=31901]  loss = 0.1579\n",
      "[iter=32001]  loss = 0.1564\n",
      "[iter=32101]  loss = 0.1618\n",
      "[iter=32201]  loss = 0.1518\n",
      "[iter=32301]  loss = 0.1563\n",
      "[iter=32401]  loss = 0.1655\n",
      "[iter=32501]  loss = 0.1588\n",
      "[iter=32601]  loss = 0.1643\n",
      "[iter=32701]  loss = 0.1612\n",
      "[iter=32801]  loss = 0.1696\n",
      "[iter=32901]  loss = 0.1578\n",
      "[iter=33001]  loss = 0.1541\n",
      "[iter=33101]  loss = 0.1579\n",
      "[iter=33201]  loss = 0.1549\n",
      "[iter=33301]  loss = 0.1588\n",
      "[iter=33401]  loss = 0.1657\n",
      "[iter=33501]  loss = 0.1565\n",
      "[iter=33601]  loss = 0.1609\n",
      "[iter=33701]  loss = 0.1594\n",
      "[iter=33801]  loss = 0.1571\n",
      "[iter=33901]  loss = 0.1540\n",
      "[iter=34001]  loss = 0.1597\n",
      "[iter=34101]  loss = 0.1656\n",
      "[iter=34201]  loss = 0.1638\n",
      "[iter=34301]  loss = 0.1591\n",
      "[iter=34401]  loss = 0.1588\n",
      "[iter=34501]  loss = 0.1681\n",
      "[iter=34601]  loss = 0.1539\n",
      "[iter=34701]  loss = 0.1558\n",
      "[iter=34801]  loss = 0.1532\n",
      "[iter=34901]  loss = 0.1588\n",
      "[iter=35001]  loss = 0.1586\n",
      "[iter=35101]  loss = 0.1498\n",
      "[iter=35201]  loss = 0.1556\n",
      "[iter=35301]  loss = 0.1530\n",
      "[iter=35401]  loss = 0.1612\n",
      "[iter=35501]  loss = 0.1450\n",
      "[iter=35601]  loss = 0.1624\n",
      "[iter=35701]  loss = 0.1712\n",
      "[iter=35801]  loss = 0.1533\n",
      "[iter=35901]  loss = 0.1639\n",
      "[iter=36001]  loss = 0.1691\n",
      "[iter=36101]  loss = 0.1572\n",
      "[iter=36201]  loss = 0.1606\n",
      "[iter=36301]  loss = 0.1729\n",
      "[iter=36401]  loss = 0.1698\n",
      "[iter=36501]  loss = 0.1585\n",
      "[iter=36601]  loss = 0.1655\n",
      "[iter=36701]  loss = 0.1559\n",
      "[iter=36801]  loss = 0.1645\n",
      "[iter=36901]  loss = 0.1671\n",
      "[iter=37001]  loss = 0.1637\n",
      "[iter=37101]  loss = 0.1559\n",
      "[iter=37201]  loss = 0.1543\n",
      "[iter=37301]  loss = 0.1582\n",
      "[iter=37401]  loss = 0.1602\n",
      "[iter=37501]  loss = 0.1643\n",
      "[iter=37601]  loss = 0.1691\n",
      "[iter=37701]  loss = 0.1598\n",
      "[iter=37801]  loss = 0.1585\n",
      "[iter=37901]  loss = 0.1699\n",
      "[iter=38001]  loss = 0.1557\n",
      "[iter=38101]  loss = 0.1522\n",
      "[iter=38201]  loss = 0.1634\n",
      "[iter=38301]  loss = 0.1614\n",
      "[iter=38401]  loss = 0.1721\n",
      "[iter=38501]  loss = 0.1659\n",
      "[iter=38601]  loss = 0.1638\n",
      "[iter=38701]  loss = 0.1642\n",
      "[iter=38801]  loss = 0.1629\n",
      "[iter=38901]  loss = 0.1698\n",
      "[iter=39001]  loss = 0.1609\n",
      "[iter=39101]  loss = 0.1694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter=39201]  loss = 0.1562\n",
      "[iter=39301]  loss = 0.1627\n",
      "[iter=39401]  loss = 0.1728\n",
      "[iter=39501]  loss = 0.1655\n",
      "[iter=39601]  loss = 0.1533\n",
      "[iter=39701]  loss = 0.1653\n",
      "[iter=39801]  loss = 0.1626\n",
      "[iter=39901]  loss = 0.1625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27c52f70a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss1 = cgp1.run_training_loop_one_neuron_model(training_data1)\n",
    "plt.plot(loss1,label = \"SGD loss\")\n",
    "\n",
    "loss2 = cgp1.run_training_loop_one_neuron_model(training_data1,0.9,True)\n",
    "plt.plot(loss2,label = \"SGD+ loss\")\n",
    "\n",
    "loss3 = cgp2.run_training_loop_one_neuron_model(training_data2,0.9,0.99)\n",
    "plt.plot(loss3,label = \"Adam loss\")\n",
    "\n",
    "plt.xlabel(\"Iterations in hundreds\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"One neuron loss using different optimizers\")\n",
    "\n",
    "plt.legend(loc = \"upper right\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826fde4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
